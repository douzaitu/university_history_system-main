import os
import pandas as pd
import json
import re
from neo4j import GraphDatabase, exceptions
import ollama
import sys
from collections import defaultdict
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv('backend/.env')

# -------------------------- DJANGO SETUP --------------------------
# æ·»åŠ  backend ç›®å½•åˆ° sys.path
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'backend.settings')

try:
    import django
    django.setup()
    from knowledge_graph.models import Entity, Relationship
    print("âœ… Django environment loaded successfully")
except Exception as e:
    print(f"âš ï¸ Failed to load Django environment: {e}")
    print("Sync to SQLite will be disabled.")
    Entity = None
    Relationship = None

# -------------------------- æ ¸å¿ƒé…ç½®ï¼ˆå¢å¼ºçº¦æŸï¼‰--------------------------
CONFIG = {
    "excel_path": "",
    "neo4j_uri": os.getenv("NEO4J_URI", "bolt://localhost:7687"),
    "neo4j_username": os.getenv("NEO4J_USERNAME", "neo4j"),
    "neo4j_password": os.getenv("NEO4J_PASSWORD", "12345678"),
    "ollama_model": "qwen2:7b",  # æ›´ç¨³å®šçš„æ¨¡å‹
    "max_text_length": 1500,
    "entity_types": [
        "æ•™å¸ˆå§“å", "é™¢ç³»", "èŒç§°", "ç ”ç©¶æ–¹å‘", "è¯¾ç¨‹åç§°", "æ¯•ä¸šé™¢æ ¡", "è£èª‰ç§°å·", "å·¥ä½œèŒè´£"
    ],
    "predefined_relations": [
        "å±äº", "æ‹¥æœ‰", "ç ”ç©¶", "ä¸»è®²", "æ¯•ä¸šäº", "è·å¾—", "è´Ÿè´£"
    ],
    "relation_mapping": {  # æ˜ç¡®å…³ç³»-å®ä½“ç±»å‹æ˜ å°„
        "å±äº": "é™¢ç³»",
        "æ‹¥æœ‰": "èŒç§°",
        "ç ”ç©¶": "ç ”ç©¶æ–¹å‘",
        "ä¸»è®²": "è¯¾ç¨‹åç§°",
        "æ¯•ä¸šäº": "æ¯•ä¸šé™¢æ ¡",
        "è·å¾—": "è£èª‰ç§°å·",
        "è´Ÿè´£": "å·¥ä½œèŒè´£"
    }
}


# -------------------------- 1. LLMå¢å¼ºçš„å®ä½“æå– --------------------------
def llm_enhance_entities(teacher_name, full_text):
    """ç”¨LLMä¿®æ­£/è¡¥å……å®ä½“æå–ç»“æœï¼Œå¤„ç†æ­£åˆ™æ— æ³•è¦†ç›–çš„å¤æ‚å¥å¼"""
    prompt = f"""
ä»…è¿”å›JSONï¼Œæ— å¤šä½™å†…å®¹ï¼
ä»»åŠ¡ï¼šä»æ–‡æœ¬ä¸­æå–{', '.join(CONFIG['entity_types'])}ï¼Œä¿®æ­£ä¸å®Œæ•´å®ä½“ï¼Œè¡¥å……é—æ¼å®ä½“ã€‚
æ³¨æ„ï¼šåŒ…å«"è´Ÿè´£"ã€"ä¸»æŒ"ã€"åˆ†ç®¡"ç­‰è¯çš„å†…å®¹å½’ç±»ä¸º"å·¥ä½œèŒè´£"ï¼Œä¸è¦å½’ç±»ä¸º"è£èª‰ç§°å·"ï¼
å·²çŸ¥å¯¼å¸ˆå§“åï¼š{teacher_name}
æ–‡æœ¬ï¼š{full_text[:CONFIG['max_text_length']]}
è¾“å‡ºæ ¼å¼ï¼š{{"æ•™å¸ˆå§“å": ["{teacher_name}"], "é™¢ç³»": [], "èŒç§°": [], "ç ”ç©¶æ–¹å‘": [], "è¯¾ç¨‹åç§°": [], "æ¯•ä¸šé™¢æ ¡": [], "è£èª‰ç§°å·": [], "å·¥ä½œèŒè´£": []}}
"""
    try:
        response = ollama.generate(
            model=CONFIG["ollama_model"],
            prompt=prompt,
            options={"temperature": 0.1, "max_tokens": 300}
        )
        # æå–å¹¶è§£æJSON
        json_str = re.search(r"\{.*\}", response["response"].strip(), re.DOTALL).group()
        llm_entities = json.loads(json_str)
        # è½¬æ¢ä¸º(å®ä½“, ç±»å‹)æ ¼å¼
        result = []
        for ent_type, ents in llm_entities.items():
            for ent in ents:
                if ent and ent.strip() and (ent.strip(), ent_type) not in result:
                    result.append((ent.strip(), ent_type))
        return result
    except Exception as e:
        print(f"LLMå®ä½“å¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æå–ï¼š{e}")
        return extract_entities_from_text_v3(teacher_name, full_text)


def extract_entities_from_text_v3(teacher_name, full_text):
    """åŸå§‹å®ä½“æå–å‡½æ•°ï¼ˆä½œä¸ºLLMå¤±è´¥çš„å¤‡ç”¨ï¼‰"""
    entities = []
    # é™¢æ ¡è¡¥å…¨æ˜ å°„è¡¨ï¼ˆæ›´å…¨é¢ï¼‰
    school_mapping = {
        "æˆéƒ½ç†å·¥å¤§": "æˆéƒ½ç†å·¥å¤§å­¦",
        "å››å·å¤§": "å››å·å¤§å­¦",
        "ç”µå­ç§‘æŠ€å¤§": "ç”µå­ç§‘æŠ€å¤§å­¦",
        "æ—¥æœ¬ä¹å·å¤§": "æ—¥æœ¬ä¹å·å¤§å­¦",
        "è¥¿å—äº¤é€šå¤§": "è¥¿å—äº¤é€šå¤§å­¦",
        "æˆéƒ½ç†å·¥å­¦": "æˆéƒ½ç†å·¥å¤§å­¦",
        "æ¸…åå¤§": "æ¸…åå¤§å­¦",
        "åŒ—äº¬å¤§": "åŒ—äº¬å¤§å­¦",
        "å¤æ—¦å¤§": "å¤æ—¦å¤§å­¦"
    }

    # åº”ç”¨é™¢æ ¡è¡¥å…¨
    for short, full in school_mapping.items():
        full_text = full_text.replace(short, full)

    # 1. æ•™å¸ˆå§“åï¼ˆå¼ºåˆ¶æ·»åŠ ï¼‰
    if teacher_name and len(teacher_name.strip()) >= 2:
        entities.append((teacher_name.strip(), "æ•™å¸ˆå§“å"))

    # 2. èŒç§°ï¼ˆæ›´ç²¾å‡†çš„æ­£åˆ™ï¼‰
    title_pattern = r"(æ•™æˆ|å‰¯æ•™æˆ|è®²å¸ˆ|åŠ©æ•™|ç ”ç©¶å‘˜|å‰¯ç ”ç©¶å‘˜|é«˜çº§å®éªŒå¸ˆ|å·¥ç¨‹å¸ˆ)"
    title_matches = re.findall(title_pattern, full_text)
    for title in title_matches:
        if title and (title, "èŒç§°") not in entities:
            entities.append((title, "èŒç§°"))

    # 3. é™¢ç³»ï¼ˆæ›´ä¸¥æ ¼çš„åŒ¹é…ï¼‰
    dept_patterns = [
        r"([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{2,10}[é™¢ç³»å­¦é™¢])",
        r"éš¶å±äº([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{2,10}[é™¢ç³»å­¦é™¢])",
        r"ä¸»æŒ([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{2,10}[é™¢ç³»å­¦é™¢])"
    ]
    for pattern in dept_patterns:
        dept_matches = re.findall(pattern, full_text)
        for match in dept_matches:
            dept = match if isinstance(match, str) else match[0]
            dept = dept.strip()
            if dept and len(dept) >= 4 and any(x in dept for x in ["é™¢", "ç³»"]) and (dept, "é™¢ç³»") not in entities:
                entities.append((dept, "é™¢ç³»"))

    # 4. å·¥ä½œèŒè´£ï¼ˆæ–°å¢ï¼‰
    work_patterns = [
        r"è´Ÿè´£([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{5,80})",
        r"ä¸»æŒ([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{5,80}å·¥ä½œ)",
        r"åˆ†ç®¡([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{5,80})"
    ]
    for pattern in work_patterns:
        work_matches = re.findall(pattern, full_text)
        for work in work_matches:
            work = work.strip()
            if len(work) > 30:
                works = re.split(r"ã€|ï¼Œ", work)
                for w in works:
                    w = w.strip()
                    if w and len(w) >= 3 and len(w) <= 20 and (w, "å·¥ä½œèŒè´£") not in entities:
                        entities.append((w, "å·¥ä½œèŒè´£"))
            elif work and len(work) >= 3 and (work, "å·¥ä½œèŒè´£") not in entities:
                entities.append((work, "å·¥ä½œèŒè´£"))

    # 5. ç ”ç©¶æ–¹å‘ï¼ˆåˆ†å‰²å¤šä¸ªæ–¹å‘ï¼‰
    research_patterns = [
        r"ç ”ç©¶æ–¹å‘[ä¸ºï¼š:\s]*([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{5,50})",
        r"ç ”ç©¶é¢†åŸŸ[ä¸ºï¼š:\s]*([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{5,50})"
    ]
    for pattern in research_patterns:
        research_matches = re.findall(pattern, full_text)
        for research in research_matches:
            # åˆ†å‰²å¤šä¸ªç ”ç©¶æ–¹å‘
            directions = re.split(r"[,ï¼Œã€;ï¼›]", research)
            for direction in directions:
                direction = direction.strip()
                if direction and len(direction) >= 3 and (direction, "ç ”ç©¶æ–¹å‘") not in entities:
                    entities.append((direction, "ç ”ç©¶æ–¹å‘"))

    # 6. è¯¾ç¨‹åç§°
    course_patterns = [
        r"ä¸»è®²[ã€Š\s]*([^ã€‹ï¼Œã€‚ï¼›ï¼š]{3,20})[ã€‹]*è¯¾",
        r"ã€Š([^ã€‹]{3,20})ã€‹"
    ]
    for pattern in course_patterns:
        course_matches = re.findall(pattern, full_text)
        for course in course_matches:
            course = course.strip()
            if course and len(course) >= 3 and (course, "è¯¾ç¨‹åç§°") not in entities:
                entities.append((course, "è¯¾ç¨‹åç§°"))

    # 7. æ¯•ä¸šé™¢æ ¡
    school_patterns = [
        r"æ¯•ä¸šäº([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{4,20}[å¤§å­¦å­¦é™¢ç ”ç©¶é™¢])",
        r"è·[ç¡•åš]å£«å­¦ä½äº([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{4,20}[å¤§å­¦å­¦é™¢])"
    ]
    for pattern in school_patterns:
        school_matches = re.findall(pattern, full_text)
        for school in school_matches:
            school = school.strip()
            if school and any(x in school for x in ["å¤§å­¦", "å­¦é™¢", "ç ”ç©¶é™¢"]) and (school, "æ¯•ä¸šé™¢æ ¡") not in entities:
                entities.append((school, "æ¯•ä¸šé™¢æ ¡"))

    # 8. è£èª‰ç§°å·
    honor_patterns = [
        r"è·å¾—([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{4,30}ç§°å·)",
        r"å…¥é€‰([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{4,30}è®¡åˆ’)",
        r"([^ï¼Œã€‚ï¼›ï¼š\(\)ï¼ˆï¼‰]{4,30}äººæ‰)"
    ]
    for pattern in honor_patterns:
        honor_matches = re.findall(pattern, full_text)
        for honor in honor_matches:
            honor = honor.strip()
            if honor and len(honor) >= 4 and (honor, "è£èª‰ç§°å·") not in entities:
                entities.append((honor, "è£èª‰ç§°å·"))

    return entities


# -------------------------- 2. LLMè‡ªæˆ‘çº é”™çš„ä¸‰å…ƒç»„ç”Ÿæˆ --------------------------
def generate_relations_with_llm_correction(entities, text, teacher_name):
    """
    (å·²ä¼˜åŒ–) ç›´æ¥æ ¹æ®æå–çš„å®ä½“å…¨é‡ç”Ÿæˆä¸‰å…ƒç»„ã€‚
    ç¬¬ä¸€æ­¥çš„LLMå®ä½“æå–å·²ç»è¶³å¤Ÿæ™ºèƒ½ï¼Œç¬¬äºŒæ­¥çš„LLMç­›é€‰åè€Œä¼šå¯¼è‡´ä¿¡æ¯ä¸¢å¤±ï¼ˆOver-filteringï¼‰ã€‚
    å› æ­¤è¿™é‡Œç›´æ¥ä½¿ç”¨è§„åˆ™å°†æ‰€æœ‰æå–å‡ºçš„å®ä½“è½¬åŒ–ä¸ºä¸‰å…ƒç»„ã€‚
    """
    entity_dict = defaultdict(list)
    for ent, typ in entities:
        if ent and typ in CONFIG["entity_types"]:
            entity_dict[typ].append(ent)

    if not entity_dict.get("æ•™å¸ˆå§“å"):
        return []

    # ç›´æ¥ä½¿ç”¨å…¨é‡è§„åˆ™ç”Ÿæˆï¼Œä¿ç•™æ‰€æœ‰æå–åˆ°çš„ä¿¡æ¯
    return generate_triples_by_rules(entity_dict, teacher_name)


# -------------------------- 3. è§„åˆ™å¼•æ“å¤‡ä»½ --------------------------
def generate_triples_by_rules(entity_dict, teacher_name):
    """ä½¿ç”¨è§„åˆ™å¼•æ“æ›¿ä»£Ollamaï¼Œç¡®ä¿ç”ŸæˆåŸºç¡€ä¸‰å…ƒç»„"""
    triples = []
    # æŒ‰å…³ç³»æ˜ å°„ç”Ÿæˆä¸‰å…ƒç»„
    for relation, entity_type in CONFIG["relation_mapping"].items():
        if entity_type in entity_dict and entity_dict[entity_type]:
            # éå†æ‰€æœ‰æœ‰æ•ˆå®ä½“ï¼Œä¸å†åªå–ç¬¬ä¸€ä¸ª
            for entity_value in entity_dict[entity_type]:
                triples.append((teacher_name, relation, entity_value))
    return triples


# -------------------------- 4. Excelè¯»å– --------------------------
def read_teacher_excel(excel_path):
    try:
        df = pd.read_excel(excel_path, engine="openpyxl")
    except Exception as e:
        raise ValueError(f"Excelè¯»å–å¤±è´¥ï¼š{str(e)}")

    excel_columns = df.columns.tolist()
    print(f"Excelè¯†åˆ«åˆ°çš„åˆ—åï¼š{excel_columns}")

    # å®šä½å§“åå’Œä¸ªäººä»‹ç»åˆ—
    name_col = next((col for col in excel_columns if any(key in str(col) for key in ["å§“å", "å¯¼å¸ˆå§“å"])), None)
    intro_col = next((col for col in excel_columns if any(key in str(col) for key in ["ä¸ªäººä»‹ç»", "è¯¦ç»†ä»‹ç»", "ç®€ä»‹", "è¯¦ç»†å†…å®¹"])),
                     None)
    if not name_col or not intro_col:
        raise ValueError(f"æ— æ³•è¯†åˆ«Excelåˆ—åã€‚æ£€æµ‹åˆ°çš„åˆ—å: {excel_columns}ã€‚è¯·ç¡®ä¿åŒ…å« 'å§“å' å’Œ 'è¯¦ç»†å†…å®¹'/'ä¸ªäººä»‹ç»' åˆ—ã€‚")

    # ç”Ÿæˆç»“æ„åŒ–æ–‡æœ¬
    structured_texts = []
    df = df.fillna("")
    for idx, row in df.iterrows():
        teacher_name = str(row[name_col]).strip().replace(" ", "").replace("ã€€", "")
        personal_intro = str(row[intro_col]).strip()
        if not teacher_name:
            print(f"ç¬¬{idx + 1}è¡Œæ— å§“åï¼Œè·³è¿‡")
            continue
        full_text = f"å¯¼å¸ˆå§“åï¼š{teacher_name}ï¼›ä¸ªäººä»‹ç»ï¼š{personal_intro[:CONFIG['max_text_length']]}"
        full_text = re.sub(r"\d{4}å¹´|\dæœˆç”Ÿ|ç”·|å¥³|é‚®ç®±ï¼š.*?[ï¼Œã€‚]", "", full_text)
        structured_texts.append({
            "index": idx + 1,
            "teacher_name": teacher_name,
            "full_text": full_text
        })
        print(f"ç¬¬{idx + 1}è¡Œï¼šå§“å={teacher_name}ï¼Œæ–‡æœ¬é•¿åº¦={len(full_text)}å­—")

    print(f"\nExcelå¤„ç†å®Œæˆï¼šå…±{len(df)}è¡Œæ•°æ®ï¼Œç”Ÿæˆ{len(structured_texts)}æ¡æœ‰æ•ˆæ–‡æœ¬")
    return structured_texts


# -------------------------- 5. Neo4jæ“ä½œ --------------------------
class Neo4jGraphManager:
    def __init__(self, uri=CONFIG["neo4j_uri"], username=CONFIG["neo4j_username"], password=CONFIG["neo4j_password"]):
        try:
            self.driver = GraphDatabase.driver(uri, auth=(username, password))
            self.driver.verify_connectivity()
            print("Neo4jè¿æ¥æˆåŠŸï¼ˆå¯è§†åŒ–åœ°å€ï¼šhttp://localhost:7474ï¼‰")
        except exceptions.AuthError:
            raise ValueError("Neo4jç”¨æˆ·å/å¯†ç é”™è¯¯")
        except exceptions.ServiceUnavailable:
            raise ConnectionError("Neo4jæœåŠ¡æœªå¯åŠ¨")
        except Exception as e:
            raise Exception(f"Neo4jåˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")

    def close(self):
        if self.driver:
            self.driver.close()
            print("ğŸ”Œ Neo4jè¿æ¥å·²å…³é—­")

    def check_entity_exists(self, name):
        """æ£€æŸ¥å®ä½“æ˜¯å¦å·²å­˜åœ¨"""
        with self.driver.session() as session:
            result = session.run("MATCH (n:Entity {name: $name}) RETURN count(n) as count", name=name)
            return result.single()["count"] > 0

    def create_triple(self, head, relation, tail):
        try:
            with self.driver.session() as session:
                session.run("""
                    MERGE (h:Entity {name: $head})
                    ON CREATE SET h.type = 'entity'
                    MERGE (t:Entity {name: $tail})
                    ON CREATE SET t.type = 'entity'
                    MERGE (h)-[r:RELATION {type: $relation}]->(t)
                    RETURN h, r, t
                """, head=head, relation=relation, tail=tail)
            
            # Sync to Django SQLite
            if Entity and Relationship:
                try:
                    # è·å–æˆ–åˆ›å»ºæºå®ä½“
                    # ç®€å•åˆ¤æ–­ç±»å‹ï¼šå¦‚æœæ˜¯æ•™å¸ˆåå­—ï¼ˆåœ¨æŸä¸ªä¸Šä¸‹æ–‡é‡ŒçŸ¥é“ï¼‰ï¼Œç±»å‹è®¾ä¸ºpersonï¼Œå¦åˆ™ä¸€èˆ¬è®¾ä¸ºentity
                    # è¿™é‡Œ reg5.py ä¸»è¦æ˜¯ä¸‰å…ƒç»„ï¼Œä¸¢å¤±äº†ç±»å‹ä¿¡æ¯ä¸Šä¸‹æ–‡ï¼Œæˆ‘ä»¬é»˜è®¤è®¾ä¸º unknown æˆ– entity
                    # å¦‚æœèƒ½åˆ¤æ–­ head æ˜¯ æ•™å¸ˆåï¼Œåˆ™ä¸º person
                    
                    src_obj, _ = Entity.objects.get_or_create(
                        name=head, 
                        defaults={'entity_type': 'organization' if 'å­¦é™¢' in head or 'å¤§å­¦' in head else 'person' if len(head) < 4 else 'event'}
                    )
                    target_obj, _ = Entity.objects.get_or_create(
                        name=tail,
                        defaults={'entity_type': 'organization' if 'å­¦é™¢' in tail or 'å¤§å­¦' in tail else 'event'}
                    )
                    
                    # ç®€å•çš„å…³ç³»æ˜ å°„
                    rel_type_map = {
                        'å±äº': 'belongs_to',
                        'ä½äº': 'located_in',
                        'å‚ä¸': 'participated_in',
                        'ä»»èŒ': 'belongs_to',
                        'æ¯•ä¸šäº': 'related_to'
                    }
                    django_rel_type = rel_type_map.get(relation, 'related_to')
                    
                    Relationship.objects.get_or_create(
                        source_entity=src_obj,
                        target_entity=target_obj,
                        relationship_type=django_rel_type,
                        defaults={'description': relation}
                    )
                    # print(f"  [SQLite] Synced: {head} -> {tail}")
                except Exception as db_e:
                    print(f"  [SQLite] Sync failed: {db_e}")

            print(f"æ’å…¥ä¸‰å…ƒç»„ï¼š({head}, {relation}, {tail})")
        except Exception as e:
            print(f"æ’å…¥å¤±è´¥ï¼š({head}, {relation}, {tail})ï¼Œé”™è¯¯ï¼š{str(e)[:50]}")

    def batch_create_triples(self, triples):
        if not triples:
            print("ï¸æ— æœ‰æ•ˆä¸‰å…ƒç»„å¯å¯¼å…¥")
            return
        print(f"\n=== æ‰¹é‡å¯¼å…¥{len(triples)}ä¸ªä¸‰å…ƒç»„ ===")
        for triple in triples:
            self.create_triple(*triple)
        print(f"=== å¯¼å…¥å®Œæˆ ===")


# -------------------------- ä¸»æµç¨‹ --------------------------
def main():

    # ç¡®å®šExcelè·¯å¾„
    if len(sys.argv) > 1:
        CONFIG["excel_path"] = sys.argv[1]
    else:
        current_dir = os.getcwd()
        # æ’é™¤ä¸´æ—¶æ–‡ä»¶ï¼ˆä»¥ ~$ å¼€å¤´ï¼‰
        excel_files = [f for f in os.listdir(current_dir) 
                      if f.endswith((".xlsx", ".xls")) 
                      and "å¯¼å¸ˆ" in f 
                      and not f.startswith("~$")]
        if excel_files:
            CONFIG["excel_path"] = os.path.join(current_dir, excel_files[0])
            print(f"è‡ªåŠ¨æ‰¾åˆ°Excelæ–‡ä»¶ï¼š{CONFIG['excel_path']}")
        else:
            print("æœªæ‰¾åˆ°å¯¼å¸ˆExcelæ–‡ä»¶")
            return

    # æ­¥éª¤1ï¼šè¯»å–Excel
    print("\nè¯»å–Excelæ•°æ®")
    try:
        structured_teachers = read_teacher_excel(CONFIG["excel_path"])
    except Exception as e:
        print(f"å¤±è´¥ï¼š{str(e)}")
        return

    # æ­¥éª¤1.5ï¼šè¿‡æ»¤å·²å­˜åœ¨çš„å¯¼å¸ˆ
    print("\næ£€æŸ¥æ•°æ®åº“ä¸­å·²å­˜åœ¨çš„å¯¼å¸ˆ...")
    try:
        neo4j_manager = Neo4jGraphManager()
        new_teachers = []
        skipped_count = 0
        
        for teacher in structured_teachers:
            if neo4j_manager.check_entity_exists(teacher["teacher_name"]):
                print(f"  [è·³è¿‡] {teacher['teacher_name']} (æ•°æ®åº“å·²å­˜åœ¨)")
                skipped_count += 1
            else:
                new_teachers.append(teacher)
        
        structured_teachers = new_teachers
        print(f"\nç­›é€‰ç»“æœï¼šå…± {len(structured_teachers) + skipped_count} æ¡ï¼Œè·³è¿‡ {skipped_count} æ¡ï¼Œå¾…å¤„ç† {len(structured_teachers)} æ¡")
        
        if not structured_teachers:
            print("æ²¡æœ‰æ–°æ•°æ®éœ€è¦å¤„ç†ã€‚")
            neo4j_manager.close()
            return

    except Exception as e:
        print(f"è¿æ¥Neo4jæ£€æŸ¥å¤±è´¥ï¼Œå°†å…¨éƒ¨å¤„ç†ï¼š{e}")
        # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œä¸ä¸­æ–­ï¼Œç»§ç»­å…¨éƒ¨å¤„ç†ï¼ˆåªæ˜¯ä¼šå¤šèŠ±ç‚¹æ—¶é—´ï¼‰

    # æ­¥éª¤2ï¼šæå–å®ä½“ï¼ˆLLMå¢å¼ºï¼‰
    print("\næ‰¹é‡æå–å®ä½“ï¼ˆLLMå¢å¼ºï¼‰")
    all_entities = []
    for teacher in structured_teachers:
        print(f"\nå¤„ç†ç¬¬{teacher['index']}ä½å¯¼å¸ˆï¼š{teacher['teacher_name']}")
        entities = llm_enhance_entities(teacher["teacher_name"], teacher["full_text"])
        print(f"æå–å®ä½“ï¼š{entities}")
        if entities:
            all_entities.append({
                "teacher_name": teacher["teacher_name"],
                "full_text": teacher["full_text"],
                "entities": entities
            })
    if not all_entities:
        print("æœªæå–åˆ°å®ä½“ï¼Œç»ˆæ­¢")
        return

    # æ­¥éª¤3ï¼šç”Ÿæˆä¸‰å…ƒç»„ï¼ˆLLMçº é”™ï¼‰
    print("\næ‰¹é‡ç”Ÿæˆä¸‰å…ƒç»„ï¼ˆLLMçº é”™ï¼‰")
    all_triples = []
    for teacher in all_entities:
        print(f"\nå¤„ç†å¯¼å¸ˆï¼š{teacher['teacher_name']}")
        triples = generate_relations_with_llm_correction(
            teacher["entities"], teacher["full_text"], teacher["teacher_name"]
        )
        if triples:
            all_triples.extend(triples)
            print(f"ğŸ”— æœ‰æ•ˆä¸‰å…ƒç»„ï¼š{triples}")
        else:
            print(f"æ— æœ‰æ•ˆä¸‰å…ƒç»„")

    # ä¸‰å…ƒç»„å»é‡
    unique_triples = list(set(tuple(t) for t in all_triples))
    print(f"\n=== ä¸‰å…ƒç»„æ±‡æ€» ===")
    print(f"åŸå§‹æ•°é‡ï¼š{len(all_triples)} | å»é‡åï¼š{len(unique_triples)}")

    # ç»Ÿè®¡å„å…³ç³»ç±»å‹æ•°é‡
    relation_count = {}
    for triple in unique_triples:
        rel = triple[1]
        relation_count[rel] = relation_count.get(rel, 0) + 1
    print(f"å…³ç³»ç±»å‹ç»Ÿè®¡ï¼š{relation_count}")

    # æ­¥éª¤4ï¼šå¯¼å…¥Neo4j
    print("\nå¯¼å…¥Neo4j")
    try:
        # å¤ç”¨ä¸Šé¢å·²ç»åˆ›å»ºçš„ neo4j_manager
        neo4j_manager.batch_create_triples(unique_triples)
        neo4j_manager.close()
    except Exception as e:
        print(f"æ­¥éª¤4å¤±è´¥ï¼š{str(e)}")
        return

    print(f"è®¿é—® http://localhost:7474")
    print(f"æ‰§è¡ŒæŸ¥è¯¢ï¼šMATCH (h:Entity)-[r:RELATION]->(t:Entity) RETURN h, r, t LIMIT 50")


if __name__ == "__main__":
    # æ£€æŸ¥OllamaæœåŠ¡
    try:
        ollama.list()
    except Exception as e:
        print(f"OllamaæœåŠ¡æœªå¯åŠ¨ï¼Œå°†ä½¿ç”¨è§„åˆ™å¼•æ“æ¨¡å¼ï¼š{str(e)}")
    main()